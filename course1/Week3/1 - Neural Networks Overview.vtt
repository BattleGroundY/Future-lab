WEBVTT

1
00 : 00 : 00.030 -> 00 : 00 : 05.279
다시 오신 것을 환영합니다.

2
00 : 00 : 02.639 -> 00 : 00 : 07.440
이번주 에는 신경망을 구현하는 법을 배울겁니다.

3
00 : 00 : 05.279 -> 00 : 00 : 09.059
기술 세부 사항을 이해하기 전에

4
00 : 00 : 07.440 -> 00 : 00 : 10.889
이 비디오에 대한 간략한 소개를하겠습니다.

5
00 : 00 : 09.059 -> 00 : 00 : 13.679
이 비디오의 모든 세부사항을

6
00 : 00 : 10.889 -> 00 : 00 : 15.389
완전히 모르더라도

7
00 : 00 : 13.679 -> 00 : 00 : 17.100
걱정 마세요.

8
00 : 00 : 15.389 -> 00 : 00 : 19.680
기술적 세부 사항은

9
00 : 00 : 17.100 -> 00 : 00 : 21.660
나중에 있는 비디오에서 자세히 설명합니다.

10
00 : 00 : 19.680 -> 00 : 00 : 24.269
지금은 여러분이 네트워크를 어떻게 구현했는지

11
00 : 00 : 21.660 -> 00 : 00 : 26.250
간단하게 복습 해보겠습니다.

12
00 : 00 : 24.269 -> 00 : 00 : 30.300
지난 주 우리는 로지스틱 회귀에 대해 이야기했습니다.

13
00 : 00 : 26.250 -> 00 : 00 : 32.430
그리고 이 모델이 다음 계산 그래프에서

14
00 : 00 : 30.300 -> 00 : 00 : 35.520
어떻게 계산 되는지를 봤습니다.

15
00 : 00 : 32.430 -> 00 : 00 : 38.370
feature x와

16
00 : 00 : 35.520 -> 00 : 00 : 40.620
매개 변수 w와 b의 연산은 z로,

17
00 : 00 : 38.370 -> 00 : 00 : 44.219
그런 다음 z에 의해 a를 계산합니다.

18
00 : 00 : 40.620 -> 00 : 00 : 47.190
그런 다음, a를 같은 변수인 y hat 으로 바꾸고

19
00 : 00 : 44.219 -> 00 : 00 : 51.059
손실 함수 L을 계산하면

20
00 : 00 : 47.190 -> 00 : 00 : 52.920
신경망이 이렇게 형성됩니다.

21
00 : 00 : 51.059 -> 00 : 00 : 54.930
전에 언급했듯이,

22
00 : 00 : 52.920 -> 00 : 00 : 57.239
sigmoid 단위 들을 쌓는 것으로도 

23
00 : 00 : 54.930 -> 00 : 01 : 00.420
신경망을 구축 할 수 있습니다.

24
00 : 00 : 57.239 -> 00 : 01 : 02.969
신경망을 만들기 위해서

25
00 : 01 : 00.420 -> 00 : 01 : 04.920
왼쪽 상단의 노드는

26
00 : 01 : 02.969 -> 00 : 01 : 07.680
두 계산 단계를 거치는데, 첫 번째 단계는 
Z 값을 계산하는 것이고

27
00 : 01 : 04.920 -> 00 : 01 : 11.640
두 번째 단계는 a의 값을 계산하는 것입니다.

28
00 : 01 : 07.680 -> 00 : 01 : 14.549
왼쪽 하단의 신경 네트워크에서

29
00 : 01 : 11.640 -> 00 : 01 : 17.880
왼쪽에서 첫번째 노드 스택은 중앙의 z 값에 해당합니다.

30
00 : 01 : 14.549 -> 00 : 01 : 21.720
그리고 왼쪽에서 첫번째 노드는

31
00 : 01 : 17.880 -> 00 : 01 : 24.090
z값과 같은 식으로 계산하십시오.

32
00 : 01 : 21.720 -> 00 : 01 : 26.790
그런 다음 왼쪽에서 두번째 노드는 
다음 z 값에 해당합니다.

33
00 : 01 : 24.090 -> 00 : 01 : 29.040
그리고 다음의 a값을 계산 하기위한 
재료 이기도 합니다.

34
00 : 01 : 26.790 -> 00 : 01 : 30.000
나중에 계산 과정에서 사용할 기호들은

35
00 : 01 : 29.040 -> 00 : 01 : 32.759
이와 같을 겁니다.

36
00 : 01 : 30.000 -> 00 : 01 : 35.430
첫 번째는 입력값 feature x

37
00 : 01 : 32.759 -> 00 : 01 : 40.320
뿐만 아니라 일부 매개 변수 w 및 b

38
00 : 01 : 35.430 -> 00 : 01 : 42.930
그래서 우리는 z1을 계산할 수 있습니다.

39
00 : 01 : 40.320 -> 00 : 01 : 45.600
여기에서 사용할 새로운 기호는 다음과 같습니다.

40
00 : 01 : 42.930 -> 00 : 01 : 48.689
우리는 오른쪽 상단에 [1]을 적을 겁니다.

41
00 : 01 : 45.600 -> 00 : 01 : 50.759
이 노드에 있는 layer를 

42
00 : 01 : 48.689 -> 00 : 01 : 53.579
표현하는데 쓰겠습니다.


43
00 : 01 : 50.759 -> 00 : 01 : 56.280
그런 다음 오른쪽 상단에 [2]를 적겠습니다.

44
00 : 01 : 53.579 -> 00 : 01 : 58.920
다음 노드 layer를

45
00 : 01 : 56.280 -> 00 : 02 : 01.200
나타 내기

46
00 : 01 : 58.920 -> 00 : 02 : 04.140
위해서 입니다.

47
00 : 02 : 01.200 -> 00 : 02 : 06.719
여기 오른쪽 위 모서리에 
소괄호를 넣지 않도록 주의하십시오.

48
00 : 02 : 04.140 -> 00 : 02 : 10.319
이 소괄호는

49
00 : 02 : 06.719 -> 00 : 02 : 12.390
우리가 각각의 training example 들을

50
00 : 02 : 10.319 -> 00 : 02 : 14.080
나타내기 위해

51
00 : 02 : 12.390 -> 00 : 02 : 16.300
사용했던 기호 입니다.

52
00 : 02 : 14.080 -> 00 : 02 : 19.030
따라서 여기에 있는 x (i)는 

53
00 : 02 : 16.300 -> 00 : 02 : 21.340
training sample을 나타내는 것이고,

54
00 : 02 : 19.030 -> 00 : 02 : 25.570
[1]과 [2]는

55
00 : 02 : 21.340 -> 00 : 02 : 28.600
신경망 상의 layer 1과 layer 2를 나타냅니다.

56
00 : 02 : 25.570 -> 00 : 02 : 32.860
우리는 z [1]을 계산한 후에

57
00 : 02 : 28.600 -> 00 : 02 : 35.350
계속해서

58
00 : 02 : 32.860 -> 00 : 02 : 39.000
로지스틱 회귀와 유사하게

59
00 : 02 : 35.350 -> 00 : 02 : 44.550
z [1]의 sigmoid 값 인 a[1]을 계산할 것입니다.

60
00 : 02 : 39.000 -> 00 : 02 : 49.270
그런 다음 다른 선형 방정식을 사용하여 
z [2]를 계산하고

61
00 : 02 : 44.550 -> 00 : 02 : 54.610
그런 다음 a [2]를 계산합니다.

62
00 : 02 : 49.270 -> 00 : 02 : 57.370
a [2] 값은

63
00 : 02 : 54.610 -> 00 : 02 : 59.890
이 신경망의 최종 결과 값이 되고

64
00 : 02 : 57.370 -> 00 : 03 : 01.390
저는 이걸 y hat 으로 표현하겠습니다.

65
00 : 02 : 59.890 -> 00 : 03 : 03.730
여기에 많은 세부 사항이 있음을 이해합니다.

66
00 : 03 : 01.390 -> 00 : 03 : 06.460
그러나 가장 중요한 점은

67
00 : 03 : 03.730 -> 00 : 03 : 09.220
이 z의 로지스틱 회귀에서는

68
00 : 03 : 06.460 -> 00 : 03 : 11.590
중앙의 식과 같이 z값에 따른 
a값을 계산 하는 것이고,

69
00 : 03 : 09.220 -> 00 : 03 : 13.780
이 신경 네트워크에서 우리는

70
00 : 03 : 11.590 -> 00 : 03 : 16.390
z값에 따른 a값 계산을 
여러번 수행 해서

71
00 : 03 : 13.780 -> 00 : 03 : 19.959
새로운 z를 통해 새로운 a를 얻어 내는 
계산을 진행하고

72
00 : 03 : 16.390 -> 00 : 03 : 22.600
마지막으로는

73
00 : 03 : 19.959 -> 00 : 03 : 24.670
최종 Loss 값을 얻어내는 것입니다.

74
00 : 03 : 22.600 -> 00 : 03 : 27.959
여러분은 로지스틱 회귀에서 back propagation을

75
00 : 03 : 24.670 -> 00 : 03 : 30.970
사용한다는 것을 기억해야 합니다.

76
00 : 03 : 27.959 -> 00 : 03 : 34.750
da dz 등등의

77
00 : 03 : 30.970 -> 00 : 03 : 36.580
혼란스러운 계산 과정들 이겠죠.

78
00 : 03 : 34.750 -> 00 : 03 : 38.860
우리는 신경 네트워크의 구축 과정에서도

79
00 : 03 : 36.580 -> 00 : 03 : 44.910
결국 이와 같은 back propagation을 사용할 것입니다.

80
00 : 03 : 38.860 -> 00 : 03 : 50.890
da [2] dz [2]를 계산할 것입니다.

81
00 : 03 : 44.910 -> 00 : 03 : 57.850
그리고 dw [2] db [2]도 마찬가지로,

82
00 : 03 : 50.890 -> 00 : 04 : 01.090
이렇게 계속 되는 겁니다.

83
00 : 03 : 57.850 -> 00 : 04 : 05.020
보시다시피 이 연산은 오른쪽에서 왼쪽으로가는

84
00 : 04 : 01.090 -> 00 : 04 : 05.360
backward calculation이고

85
00 : 04 : 05.020 -> 00 : 04 : 07.970
빨간색 화살표입니다.

86
00 : 04 : 05.360 -> 00 : 04 : 09.770
신경망을 어떻게 구현 하는지에 대해서

87
00 : 04 : 07.970 -> 00 : 04 : 12.950
오늘 우리는 간단한 개요를 보았습니다.

88
00 : 04 : 09.770 -> 00 : 04 : 14.630
로지스틱 회귀를 가져와서 
이 과정을 두 번 반복 하면 되는겁니다.

89
00 : 04 : 12.950 -> 00 : 04 : 16.880
오늘의 비디오에는 새로운 지식이 
많이 있었다는 것을 이해합니다.

90
00 : 04 : 14.630 -> 00 : 04 : 18.980
새로운 지식 정보에 대해서는 걱정하지 마십시오.

91
00 : 04 : 16.880 -> 00 : 04 : 20.900
다음 몇 가지 비디오에서

92
00 : 04 : 18.980 -> 00 : 04 : 22.820
천천히 세부 사항을 설명 할 것입니다.

93
00 : 04 : 20.900 -> 00 : 04 : 24.620
다음 강의로 넘어 갑시다.

94
00 : 04 : 22.820 -> 00 : 04 : 27.850
신경망 표현에 관한 얘기를

95
00 : 04 : 24.620 -> 00 : 04 : 27.850
더 해보도록 하겠습니다.